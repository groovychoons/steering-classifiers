{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset as HFDataset\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from dialz import Dataset, SteeringModel, SteeringVector, get_activation_score\n",
    "from score import get_unaggregated_activation_score\n",
    "from models import construct_dataset, optimize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "\n",
    "df = pd.read_csv(\"../data/hate_speech_binary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "## Steering vector\n",
    "def compute_activation_score(\n",
    "        df: pd.DataFrame,\n",
    "        scoring_method: str,\n",
    "        model_name: str, \n",
    "        items: list, \n",
    "        prompt_type: str, \n",
    "        num_sents: int,\n",
    "        system_role: str,\n",
    "    ):\n",
    "    dataset = Dataset.create_dataset(model_name, items, prompt_type=prompt_type, num_sents=num_sents, system_role=system_role)\n",
    "    \n",
    "    model = SteeringModel(model_name, list(range(-5, -18, -1)), hf_token)\n",
    "    vector = SteeringVector.train(model, dataset)\n",
    "    max_token_length = 0\n",
    "    activation_scores = []\n",
    "    unaggregated_activation_scores = []\n",
    "\n",
    "    for i, text in tqdm(enumerate(df['text']), total=len(df), desc=\"Calculating activation scores\"):\n",
    "        activation_score, token_length, unaggregated_activation_score = get_unaggregated_activation_score(text, model, vector, layer_index=list(range(15, 20, 1)), \n",
    "                                                                                                          scoring_method=scoring_method)\n",
    "        activation_scores.append(activation_score)\n",
    "        unaggregated_activation_scores.append(unaggregated_activation_score)\n",
    "        max_token_length = max(max_token_length, token_length)\n",
    "        df.at[i, 'activation_score'] = activation_score\n",
    "        df.at[i, 'token_length'] = token_length\n",
    "    print(f\"Max token length: {max_token_length}\")\n",
    "\n",
    "    # Pad activation scores to max token length\n",
    "    print(\"Padding activation scores to max token length after tokenization.\")\n",
    "    padded_activation_scores = np.full((len(df.text), 5, max_token_length), 0, dtype=float)\n",
    "    for i, scores in enumerate(unaggregated_activation_scores):\n",
    "        for j, score in enumerate(scores):\n",
    "            length = len(score)\n",
    "            padded_activation_scores[i, j, :length] = score\n",
    "\n",
    "    return df, padded_activation_scores, max_token_length\n",
    "\n",
    "\n",
    "def run_classifier(\n",
    "        df: pd.DataFrame,\n",
    "        scoring_method: str,\n",
    "        model_name: str, \n",
    "        items: list, \n",
    "        prompt_type: str, \n",
    "        num_sents: int,\n",
    "        system_role: str,\n",
    "    ):\n",
    "    df, padded_activation_scores, max_token_length = compute_activation_score(df, scoring_method, model_name, items, prompt_type, num_sents, system_role)\n",
    "\n",
    "    # different classifiers\n",
    "    results = {}\n",
    "\n",
    "    # threshold-based classifier\n",
    "    def calculate_score(scores_df, label_0_condition, label_1_condition):\n",
    "        label_0_count = ((scores_df['label'] == 0) & label_0_condition).sum()\n",
    "        label_1_count = ((scores_df['label'] == 1) & label_1_condition).sum()\n",
    "        return label_0_count + label_1_count\n",
    "\n",
    "    # Generate a range of thresholds to test\n",
    "    thresholds = np.linspace(df['activation_score'].min(), df['activation_score'].max(), 1000)\n",
    "    condition = [calculate_score(df, df['activation_score'] < t, df['activation_score'] > t) for t in thresholds]\n",
    "    best_threshold = thresholds[np.argmax(condition)]\n",
    "    accuracy_condition = (np.max(condition) / len(df)) * 100\n",
    "    results['threshold_classifier'] = accuracy_condition\n",
    "    print(f\"Best threshold: {best_threshold}\")\n",
    "    print(f\"Accuracy: {accuracy_condition:.2f}%\")\n",
    "    \n",
    "    # Constructing the dataset for training and testing\n",
    "    train_dataset, test_dataset = construct_dataset(df, padded_activation_scores, test_size=0.3, random_state=42)\n",
    "    #train_dataset = HFDataset.from_dict({\"text\": train_dataset.activation_score, \"label\": [np.argwhere(label)[0][0] for label in train_dataset.labels]})\n",
    "    #test_dataset = HFDataset.from_dict({\"text\": test_dataset.activation_score, \"label\": [np.argwhere(label)[0][0] for label in test_dataset.labels]})\n",
    "\n",
    "    # Learning a linear classifier\n",
    "    acc = optimize(train_dataset, test_dataset, max_token_length, learning_rate=1e-3, batch_size=64, epochs=50, is_transformer=False)\n",
    "    results['linear_classifier'] = acc\n",
    "    print(f\"Accuracy for linear layer: {acc:.2f}%\")\n",
    "\n",
    "    # Learning a transformer-based classifier\n",
    "    acc = optimize(train_dataset, test_dataset, max_token_length, learning_rate=1e-3, batch_size=64, epochs=50, is_transformer=True)\n",
    "    results['transformer_classifier'] = acc\n",
    "    print(f\"Accuracy for transformer feature learner and then a linear classifier: {acc:.2f}%\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of label 1s: 54.60%\n",
      "Percentage of label 0s: 45.40%\n"
     ]
    }
   ],
   "source": [
    "df_2 = df.sample(n=500, random_state=42).reset_index(drop=True)\n",
    "\n",
    "label_1_percentage = (df_2['label'].value_counts(normalize=True)[1] * 100)\n",
    "label_0_percentage = (df_2['label'].value_counts(normalize=True)[0] * 100)\n",
    "\n",
    "print(f\"Percentage of label 1s: {label_1_percentage:.2f}%\")\n",
    "print(f\"Percentage of label 0s: {label_0_percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.05it/s]\n",
      "100%|██████████| 25/25 [00:05<00:00,  4.42it/s]\n",
      "100%|██████████| 31/31 [00:02<00:00, 13.87it/s]\n",
      "Calculating activation scores: 100%|██████████| 500/500 [03:56<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max token length: 172\n",
      "Padding activation scores to max token length after tokenization.\n",
      "Best threshold: 1.4273427373296148\n",
      "Accuracy: 86.80%\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.682186  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 67.3%, Avg loss: 0.611222 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.572054  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 0.581185 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.538681  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 74.0%, Avg loss: 0.557042 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.471599  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 0.540874 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.486430  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.526084 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.461655  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.513361 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.476743  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.503089 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.475239  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.490423 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.403506  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.481636 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.407269  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.476999 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.442428  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.468255 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.405105  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.465566 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.421348  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.462071 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.400080  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.458359 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.446955  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.456572 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.388356  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.453548 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.401937  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.451793 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.381730  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.450545 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.406389  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.448191 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.422823  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.448260 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.386692  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.447567 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.393091  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.449380 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.397177  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.447437 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.358883  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.448445 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.393652  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.447398 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.358212  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.447327 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.369646  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.444632 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.351801  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.444384 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.399197  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.446030 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.353846  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.447605 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.384938  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.446541 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.354960  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.445038 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.395341  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.444948 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.388061  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.445988 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.338955  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.447993 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.377814  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.448996 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.403163  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.449522 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.381325  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.448002 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.381592  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.449028 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.360062  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.451307 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.331485  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.450936 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.349615  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.451243 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.387875  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.449929 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.370159  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.451386 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.348943  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.451714 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.387360  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.450574 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.348622  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.450927 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.365769  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.451106 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.354569  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.450815 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.362508  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.453578 \n",
      "\n",
      "Done!\n",
      "Accuracy for linear layer: 0.86%\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.708203  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 0.564363 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.528393  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.517342 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.487394  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.488685 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.467347  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.480301 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.389416  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.477816 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.356416  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.477726 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.420748  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.471247 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.390595  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.464904 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.370253  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.449479 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.426207  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.444983 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.362690  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.461566 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.410911  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.458288 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.363212  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.460512 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.346802  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.479205 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.348242  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.462989 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.377958  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.455431 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.366847  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.451408 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.369764  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.456354 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.361289  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.467565 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.410476  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.450464 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.403242  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.440623 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.345000  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.442442 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.344977  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.471273 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.438237  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.451198 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.328340  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.437483 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.364207  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.448842 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.428557  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.451610 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.321766  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.439557 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.359883  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.439974 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.333731  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.450210 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.343095  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.455791 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.411896  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.446210 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.388041  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.446853 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.363066  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.448188 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.352932  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.511734 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.399714  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.432427 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.350300  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.436821 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.333490  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.450412 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.329471  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.446840 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.339938  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.436598 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.314463  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.452152 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.379699  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.446024 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.344772  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.449295 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.329297  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.445792 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.329377  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.456057 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.329050  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.469276 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.313565  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.456063 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.346436  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.460236 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.321671  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.449092 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.376215  [   64/  350]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.426177 \n",
      "\n",
      "Done!\n",
      "Accuracy for transformer feature learner and then a linear classifier: 0.86%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'threshold_classifier': np.float64(86.8),\n",
       " 'linear_classifier': 0.86,\n",
       " 'transformer_classifier': 0.86}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_classifier(df_2, 'max_token', model_name, ['hate speech', 'loving words'], 'sentence-starters', 400, 'You are an example of how someone would respond with ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with textual features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 350/350 [00:00<00:00, 3061.97 examples/s]\n",
      "Map: 100%|██████████| 150/150 [00:00<00:00, 4837.20 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 00:45, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.228227</td>\n",
       "      <td>0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.212520</td>\n",
       "      <td>0.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.164131</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=132, training_loss=0.27294476826985675, metrics={'train_runtime': 45.5943, 'train_samples_per_second': 23.029, 'train_steps_per_second': 2.895, 'total_flos': 276266608128000.0, 'train_loss': 0.27294476826985675, 'epoch': 3.0})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"google-bert/bert-base-cased\", num_labels=2)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-cased\")\n",
    "\n",
    "def tokenize(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "train_dataset_hf = HFDataset.from_dict({\"text\": train_dataset.text, \"label\": [np.argwhere(label)[0][0] for label in train_dataset.labels]})\n",
    "test_dataset_hf = HFDataset.from_dict({\"text\": test_dataset.text, \"label\": [np.argwhere(label)[0][0] for label in test_dataset.labels]})\n",
    "train_dataset_hf = train_dataset_hf.map(tokenize, batched=True)\n",
    "test_dataset_hf = test_dataset_hf.map(tokenize, batched=True)\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    # convert the logits to their predicted class\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    push_to_hub=False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset_hf,\n",
    "    eval_dataset=test_dataset_hf,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"prompt\": \"You are a crazy extremist who only responds with absolute \",\n",
    "# \"contrastive_words\": [\"hate\", \"love\"]\n",
    "# acc: 83.60%\n",
    "\n",
    "print('Test 2')\n",
    "test2 = test_dataset(df_2, 'mean', model_name, ['hate speech', 'loving words'], 'sentence-starters', 400, 'You are an example of how someone would respond with ')\n",
    "\n",
    "print('Test 3')\n",
    "test3 = test_dataset(df_2, 'final_token', model_name, ['hate speech', 'loving words'], 'sentence-starters', 400, 'You are an example of how someone would respond with ')\n",
    "\n",
    "print('Test 4')\n",
    "test4 = test_dataset(df_2, 'max_token', model_name, ['hate speech', 'loving words'], 'sentence-starters', 400, 'You are an example of how someone would respond with ')\n",
    "\n",
    "print('Test 5')\n",
    "test5 = test_dataset(df_2, 'median_token', model_name, ['hate speech', 'loving words'], 'sentence-starters', 400, 'You are an example of how someone would respond with ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then test scoring_methods default, last_token, max_token, median_token\n",
    "# test alla the different layer options\n",
    "\n",
    "methods = ['mean', 'final_token', 'max_token', 'median_token']\n",
    "setup = {\n",
    "    \"prompt\": \"You are a crazy extremist who only responds with absolute \",\n",
    "    \"contrastive_words\": [\"hate\", \"love\"]\n",
    "}\n",
    "\n",
    "for method in methods:\n",
    "    print(method)\n",
    "    test_dataset(df_2, method, model_name, setup[\"contrastive_words\"], 'starters', 400, setup[\"prompt\"])\n",
    "\n",
    "setup_2 = {\n",
    "    \"prompt\": \"You are an example of how someone would respond with \",\n",
    "    \"contrastive_words\": [\"hate speech\", \"loving words\"]\n",
    "}\n",
    "\n",
    "for method in methods:\n",
    "    print(method)\n",
    "    test_dataset(df_2, method, model_name, setup[\"contrastive_words\"], 'starters', 400, setup[\"prompt\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = test4['activation_score'].median()\n",
    "max_value = test4['activation_score'].max()\n",
    "min_value = test4['activation_score'].min()\n",
    "\n",
    "print(f\"Median: {median}\")\n",
    "print(f\"Max: {max_value}\")\n",
    "print(f\"Min: {min_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.create_dataset(model_name, ['hate speech', 'loving words'], 'starters', 400, 'You are an example of how someone would respond with ')\n",
    "\n",
    "model = SteeringModel(model_name, list(range(-5, -18, -1)), hf_token)\n",
    "vector = SteeringVector.train(model, dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filter 10 texts with label 0 and 10 texts with label 1\n",
    "label_0_texts = df[df['label'] == 0].head(10)\n",
    "label_1_texts = df[df['label'] == 1].head(10)\n",
    "print(len(label_1_texts))\n",
    "# Process and print activation visualization and scores for label 0 texts\n",
    "print(\"Activation visualization and scores for label 0 texts:\")\n",
    "for i, row in label_0_texts.iterrows():\n",
    "    text = row['text']\n",
    "    activation_visualization = model.visualize_activation(input_text=text, control_vector=vector)\n",
    "    activation_score = get_activation_score(text, model, vector, layer_index=20)\n",
    "    print(f\"Row {i}:\\nText: {text}\\nActivation Visualization:\\n{activation_visualization}\\nActivation Score: {activation_score}\\n\")\n",
    "\n",
    "print(\"=====================================\")\n",
    "print(\"=====================================\")\n",
    "\n",
    "# Process and print activation visualization and scores for label 1 texts\n",
    "print(\"Activation visualization and scores for label 1 texts:\")\n",
    "for i, row in label_1_texts.iterrows():\n",
    "    text = row['text']\n",
    "    activation_visualization = model.visualize_activation(input_text=text, control_vector=vector)\n",
    "    activation_score = get_activation_score(text, model, vector, layer_index=20)\n",
    "    print(f\"Row {i}:\\nText: {text}\\nActivation Visualization:\\n{activation_visualization}\\nActivation Score: {activation_score}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_strings = []\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, token=model.token)\n",
    "tokenizer.pad_token_id = 0\n",
    "\n",
    "def generate_with_vector(\n",
    "    input: str,\n",
    "    vector: SteeringVector,\n",
    "    coeffs: tuple[float, float],\n",
    "    max_new_tokens: int = 20,\n",
    "    repetition_penalty: float = 1.1,\n",
    "    show_baseline: bool = True,\n",
    "):\n",
    "    positive_coeff, negative_coeff = coeffs\n",
    "    assert positive_coeff > 0\n",
    "    assert negative_coeff < 0\n",
    "\n",
    "    input_ids = tokenizer(input, return_tensors=\"pt\").to(model.device)\n",
    "    settings = {\n",
    "        \"pad_token_id\": tokenizer.eos_token_id,  # silence warning\n",
    "        \"do_sample\": False,  # temperature=0\n",
    "        \"max_new_tokens\": max_new_tokens,\n",
    "        \"repetition_penalty\": repetition_penalty,\n",
    "    }\n",
    "\n",
    "    if show_baseline:\n",
    "        print(\"==baseline ---------------------------------------------------\")\n",
    "        model.reset()\n",
    "        print(\n",
    "            tokenizer.decode(model.generate(**input_ids, **settings).squeeze()).strip()\n",
    "        )\n",
    "        list_of_strings.append(\n",
    "            tokenizer.decode(model.generate(**input_ids, **settings).squeeze()).strip()\n",
    "        )\n",
    "\n",
    "    print(\"\\n++control ---------------------------------------------------\")\n",
    "    model.set_control(vector, positive_coeff)\n",
    "    print(tokenizer.decode(model.generate(**input_ids, **settings).squeeze()).strip())\n",
    "    list_of_strings.append(\n",
    "        tokenizer.decode(model.generate(**input_ids, **settings).squeeze()).strip()\n",
    "    )\n",
    "\n",
    "    print(\"\\n--control ---------------------------------------------------\")\n",
    "    model.set_control(vector, negative_coeff)\n",
    "    print(tokenizer.decode(model.generate(**input_ids, **settings).squeeze()).strip())\n",
    "    list_of_strings.append(\n",
    "        tokenizer.decode(model.generate(**input_ids, **settings).squeeze()).strip()\n",
    "    )\n",
    "\n",
    "    model.reset()\n",
    "\n",
    "    with open(f\"output_{input[:10]}.txt\", \"w\") as f:\n",
    "        for string in list_of_strings:\n",
    "            f.write(string + \"\\n\")\n",
    "\n",
    "\n",
    "generate_with_vector(\"Write about a black man.\", vector, (2,-2), 60)\n",
    "\n",
    "\n",
    "\n",
    "# highlighted_output = model.visualize_activation(\n",
    "#     input_text=\"Good CEOs are all men. Men tend to be better at leadership roles.\",\n",
    "#     control_vector=vector,\n",
    "# )\n",
    "\n",
    "# print(highlighted_output)\n",
    "\n",
    "# highlighted_output = model.visualize_activation(\n",
    "#     input_text=\"Women are supposed to stay in the kitchen not go out and become nurses.\",\n",
    "#     control_vector=vector,\n",
    "# )\n",
    "# print(highlighted_output)\n",
    "\n",
    "# highlighted_output = model.visualize_activation(\n",
    "#     input_text=\"Mothers are the most amazing thing to bless humankind.\",\n",
    "#     control_vector=vector,\n",
    "# )\n",
    "# print(highlighted_output)\n",
    "\n",
    "# print(\n",
    "#     get_activation_score(\"Female empowerment is an amazing thing.\", model, vector)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "def classify_hate_speech(text):\n",
    "    try:\n",
    "        response = client.responses.create(\n",
    "            model=\"gpt-4o\",\n",
    "            instructions=\"You are a helpful assistant that classifies text as hate speech or not.\",\n",
    "            input=f\"Is the following text hate speech? Respond only with 0 for no and 1 for yes: {text}\",\n",
    "        )\n",
    "        result = response.output_text\n",
    "        return int(result) if result in ['0', '1'] else None\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {text}\\nError: {e}\")\n",
    "        return None\n",
    "\n",
    "openai_results = df_2.copy()\n",
    "openai_results['openai'] = openai_results['text'].apply(classify_hate_speech)\n",
    "openai_results.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of None (missing) values in the predictions\n",
    "none_count = openai_results['openai'].isna().sum()\n",
    "print(f\"Number of None values in predictions: {none_count}\")\n",
    "\n",
    "# Filter out rows where the prediction is None\n",
    "valid_predictions = openai_results[openai_results['openai'].notna()]\n",
    "\n",
    "# Count how many predictions match the ground truth label\n",
    "correct_count = (valid_predictions['openai'] == valid_predictions['label']).sum()\n",
    "total_valid = len(valid_predictions)\n",
    "accuracy = (correct_count / total_valid) * 100 if total_valid > 0 else 0\n",
    "\n",
    "print(f\"Number of correctly classified texts: {correct_count} out of {total_valid}\")\n",
    "print(f\"Accuracy (excluding None values): {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows where the prediction is None\n",
    "none_rows = openai_results[openai_results['openai'].isna()]\n",
    "print(\"Texts with None predictions:\")\n",
    "for idx, row in none_rows.iterrows():\n",
    "    print(f\"Index {idx}: {row['text']}\")\n",
    "    \n",
    "# Rows where the prediction is not None but misclassified\n",
    "misclassified = openai_results[\n",
    "    (openai_results['openai'].notna()) &\n",
    "    (openai_results['openai'] != openai_results['label'])\n",
    "]\n",
    "print(\"\\nTexts with misclassified values:\")\n",
    "for idx, row in misclassified.iterrows():\n",
    "    print(f\"Index {idx}:\")\n",
    "    print(f\"Text: {row['text']}\")\n",
    "    print(f\"Ground Truth: {row['label']}, Prediction: {row['openai']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "debias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
