{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from dialz import Dataset, SteeringModel, SteeringVector, visualize_activation\n",
    "\n",
    "load_dotenv()\n",
    "hf_token = os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72f2cc697a2a4c359d6ef1e767973a22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m dataset \u001b[38;5;241m=\u001b[39m Dataset\u001b[38;5;241m.\u001b[39mload_dataset(model_name, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmorality\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m## Initialize a steering model that activates on layers 10 to 19\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSteeringModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_token\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m## Train the steering vector using the above model and dataset\u001b[39;00m\n\u001b[1;32m      7\u001b[0m vector \u001b[38;5;241m=\u001b[39m SteeringVector\u001b[38;5;241m.\u001b[39mtrain(model, dataset)\n",
      "File \u001b[0;32m~/miniforge3/envs/debias/lib/python3.10/site-packages/dialz/vector.py:345\u001b[0m, in \u001b[0;36mSteeringModel.__init__\u001b[0;34m(self, model_name, layer_ids, token)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name, token\u001b[38;5;241m=\u001b[39mtoken, torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16\n\u001b[1;32m    342\u001b[0m )\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken \u001b[38;5;241m=\u001b[39m token\n\u001b[0;32m--> 345\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda:0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmps:0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmps\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    349\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m layers \u001b[38;5;241m=\u001b[39m model_layer_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_ids \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(layers) \u001b[38;5;241m+\u001b[39m i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m layer_ids]\n",
      "File \u001b[0;32m~/miniforge3/envs/debias/lib/python3.10/site-packages/transformers/modeling_utils.py:3698\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[1;32m   3694\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3695\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3696\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3697\u001b[0m         )\n\u001b[0;32m-> 3698\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/debias/lib/python3.10/site-packages/torch/nn/modules/module.py:1355\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1352\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1353\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/debias/lib/python3.10/site-packages/torch/nn/modules/module.py:915\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 915\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    919\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    920\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    926\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/debias/lib/python3.10/site-packages/torch/nn/modules/module.py:915\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 915\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    919\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    920\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    926\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 915 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/debias/lib/python3.10/site-packages/torch/nn/modules/module.py:915\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 915\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    919\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    920\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    926\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/debias/lib/python3.10/site-packages/torch/nn/modules/module.py:942\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 942\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    943\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    945\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/debias/lib/python3.10/site-packages/torch/nn/modules/module.py:1341\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1334\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1335\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1336\u001b[0m             device,\n\u001b[1;32m   1337\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1338\u001b[0m             non_blocking,\n\u001b[1;32m   1339\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1340\u001b[0m         )\n\u001b[0;32m-> 1341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1345\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "dataset = Dataset.load_dataset(model_name, 'morality')\n",
    "## Initialize a steering model that activates on layers 10 to 19\n",
    "model = SteeringModel(model_name, layer_ids=list(range(10,20)), token=hf_token)\n",
    "\n",
    "## Train the steering vector using the above model and dataset\n",
    "vector = SteeringVector.train(model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[48;2;255;154;154m\u001b[38;2;0;0;0mThe\u001b[0m\u001b[48;2;255;251;251m\u001b[38;2;0;0;0m Statue\u001b[0m\u001b[48;2;255;179;179m\u001b[38;2;0;0;0m of\u001b[0m\u001b[48;2;255;130;130m\u001b[38;2;0;0;0m Liberty\u001b[0m\u001b[48;2;236;252;250m\u001b[38;2;0;0;0m is\u001b[0m\u001b[48;2;255;171;171m\u001b[38;2;0;0;0m in\u001b[0m\u001b[48;2;255;174;174m\u001b[38;2;0;0;0m New\u001b[0m\u001b[48;2;255;209;209m\u001b[38;2;0;0;0m York\u001b[0m\u001b[48;2;255;102;102m\u001b[38;2;0;0;0m City\u001b[0m\u001b[48;2;255;255;255m\u001b[38;2;0;0;0m.\u001b[0m \t \u001b[48;2;255;163;163m\u001b[38;2;0;0;0mThe\u001b[0m\u001b[48;2;255;252;252m\u001b[38;2;0;0;0m Statue\u001b[0m\u001b[48;2;255;186;186m\u001b[38;2;0;0;0m of\u001b[0m\u001b[48;2;255;141;141m\u001b[38;2;0;0;0m Liberty\u001b[0m\u001b[48;2;238;252;250m\u001b[38;2;0;0;0m is\u001b[0m\u001b[48;2;255;141;141m\u001b[38;2;0;0;0m in\u001b[0m\u001b[48;2;200;246;241m\u001b[38;2;0;0;0m Cardiff\u001b[0m\u001b[48;2;255;239;239m\u001b[38;2;0;0;0m,\u001b[0m\u001b[48;2;64;224;208m\u001b[38;2;0;0;0m Wales\u001b[0m\u001b[48;2;255;255;255m\u001b[38;2;0;0;0m.\u001b[0m\n",
      "\u001b[48;2;255;190;190m\u001b[38;2;0;0;0mThe\u001b[0m\u001b[48;2;255;177;177m\u001b[38;2;0;0;0m E\u001b[0m\u001b[48;2;255;102;102m\u001b[38;2;0;0;0miff\u001b[0m\u001b[48;2;255;123;123m\u001b[38;2;0;0;0mel\u001b[0m\u001b[48;2;255;119;119m\u001b[38;2;0;0;0m Tower\u001b[0m\u001b[48;2;255;197;197m\u001b[38;2;0;0;0m is\u001b[0m\u001b[48;2;255;159;159m\u001b[38;2;0;0;0m in\u001b[0m\u001b[48;2;255;102;102m\u001b[38;2;0;0;0m Paris\u001b[0m\u001b[48;2;255;255;255m\u001b[38;2;0;0;0m.\u001b[0m \t\t\t \u001b[48;2;255;223;223m\u001b[38;2;0;0;0mThe\u001b[0m\u001b[48;2;255;217;217m\u001b[38;2;0;0;0m E\u001b[0m\u001b[48;2;255;180;180m\u001b[38;2;0;0;0miff\u001b[0m\u001b[48;2;255;190;190m\u001b[38;2;0;0;0mel\u001b[0m\u001b[48;2;255;188;188m\u001b[38;2;0;0;0m Tower\u001b[0m\u001b[48;2;255;226;226m\u001b[38;2;0;0;0m is\u001b[0m\u001b[48;2;211;247;244m\u001b[38;2;0;0;0m in\u001b[0m\u001b[48;2;64;224;208m\u001b[38;2;0;0;0m Rome\u001b[0m\u001b[48;2;255;255;255m\u001b[38;2;0;0;0m.\u001b[0m\n",
      "\u001b[48;2;255;190;190m\u001b[38;2;0;0;0mPl\u001b[0m\u001b[48;2;255;102;102m\u001b[38;2;0;0;0mants\u001b[0m\u001b[48;2;255;193;193m\u001b[38;2;0;0;0m need\u001b[0m\u001b[48;2;226;250;248m\u001b[38;2;0;0;0m light\u001b[0m\u001b[48;2;255;103;103m\u001b[38;2;0;0;0m and\u001b[0m\u001b[48;2;255;213;213m\u001b[38;2;0;0;0m water\u001b[0m\u001b[48;2;255;215;215m\u001b[38;2;0;0;0m to\u001b[0m\u001b[48;2;255;121;121m\u001b[38;2;0;0;0m grow\u001b[0m\u001b[48;2;255;255;255m\u001b[38;2;0;0;0m.\u001b[0m \t\t \u001b[48;2;255;210;210m\u001b[38;2;0;0;0mPl\u001b[0m\u001b[48;2;255;148;148m\u001b[38;2;0;0;0mants\u001b[0m\u001b[48;2;224;250;247m\u001b[38;2;0;0;0m need\u001b[0m\u001b[48;2;255;197;197m\u001b[38;2;0;0;0m chocolate\u001b[0m\u001b[48;2;255;210;210m\u001b[38;2;0;0;0m and\u001b[0m\u001b[48;2;255;162;162m\u001b[38;2;0;0;0m wine\u001b[0m\u001b[48;2;255;193;193m\u001b[38;2;0;0;0m to\u001b[0m\u001b[48;2;64;224;208m\u001b[38;2;0;0;0m grow\u001b[0m\u001b[48;2;255;255;255m\u001b[38;2;0;0;0m.\u001b[0m\n",
      "\u001b[48;2;255;114;114m\u001b[38;2;0;0;0mSh\u001b[0m\u001b[48;2;220;249;246m\u001b[38;2;0;0;0makespeare\u001b[0m\u001b[48;2;255;147;147m\u001b[38;2;0;0;0m wrote\u001b[0m\u001b[48;2;255;103;103m\u001b[38;2;0;0;0m Ham\u001b[0m\u001b[48;2;255;102;102m\u001b[38;2;0;0;0mlet\u001b[0m\u001b[48;2;255;255;255m\u001b[38;2;0;0;0m.\u001b[0m \t\t\t \u001b[48;2;255;193;193m\u001b[38;2;0;0;0mSh\u001b[0m\u001b[48;2;240;252;251m\u001b[38;2;0;0;0makespeare\u001b[0m\u001b[48;2;255;248;248m\u001b[38;2;0;0;0m wrote\u001b[0m\u001b[48;2;239;252;251m\u001b[38;2;0;0;0m The\u001b[0m\u001b[48;2;255;204;204m\u001b[38;2;0;0;0m Hunger\u001b[0m\u001b[48;2;64;224;208m\u001b[38;2;0;0;0m Games\u001b[0m\u001b[48;2;255;255;255m\u001b[38;2;0;0;0m.\u001b[0m\n",
      "\u001b[48;2;255;200;200m\u001b[38;2;0;0;0mP\u001b[0m\u001b[48;2;241;252;251m\u001b[38;2;0;0;0menguins\u001b[0m\u001b[48;2;255;235;235m\u001b[38;2;0;0;0m live\u001b[0m\u001b[48;2;255;211;211m\u001b[38;2;0;0;0m in\u001b[0m\u001b[48;2;255;251;251m\u001b[38;2;0;0;0m the\u001b[0m\u001b[48;2;255;134;134m\u001b[38;2;0;0;0m Southern\u001b[0m\u001b[48;2;255;102;102m\u001b[38;2;0;0;0m Hemisphere\u001b[0m\u001b[48;2;255;255;255m\u001b[38;2;0;0;0m.\u001b[0m \t \u001b[48;2;255;219;219m\u001b[38;2;0;0;0mP\u001b[0m\u001b[48;2;246;253;252m\u001b[38;2;0;0;0menguins\u001b[0m\u001b[48;2;255;242;242m\u001b[38;2;0;0;0m live\u001b[0m\u001b[48;2;255;227;227m\u001b[38;2;0;0;0m in\u001b[0m\u001b[48;2;239;252;251m\u001b[38;2;0;0;0m the\u001b[0m\u001b[48;2;208;247;243m\u001b[38;2;0;0;0m Sahara\u001b[0m\u001b[48;2;64;224;208m\u001b[38;2;0;0;0m Desert\u001b[0m\u001b[48;2;255;255;255m\u001b[38;2;0;0;0m.\u001b[0m\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"../data/hate_speech_binary.csv\")\n",
    "\n",
    "hate_texts = df.nlargest(5, 'hate_speech_score')['text'].tolist()\n",
    "love_texts = df.nlargest(5, 'hate_speech_score')['text'].tolist()\n",
    "\n",
    "longest_hate_text = df[df['label'] == 1].loc[df['text'].str.len().idxmax()]['text']\n",
    "longest_love_text = df[df['label'] == 0].loc[df['text'].str.len().idxmax()]['text']\n",
    "\n",
    "for layer in range(1,32):\n",
    "    print(f\"Layer {layer}: \\t\" + (visualize_activation(hate_texts[0], model, vector, layer_index=layer)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "debias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
